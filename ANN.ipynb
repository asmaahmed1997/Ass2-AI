{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20911b16908>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X= np.array([[300,99,6.8],[308],[308,103,8.36],[329,110,9.15],[332,118,9.36]])\n",
    "TL_data= np.array([[0.36,0.7,0.84,0.9]])\n",
    "\n",
    "W1=np.random.randn()\n",
    "W2=np.random.randn()\n",
    "W3=np.random.randn()\n",
    "W4=np.random.randn()\n",
    "\n",
    "r=np.linspace(-10,10,100)\n",
    "e= sigmoid(r)\n",
    "plt.plot(r,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEED-FORWARD\n",
    "#for epoch in range(4):\n",
    "   # R = X.dot(W[0])+B[0] # linear response\n",
    "   # H1= sigmoid( R ) # activation f’n\n",
    "   # S = H1.dot(W[1])+B[1] # linear response\n",
    "   # H2 = sigmoid( S ) # activation f’n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKPROPAGATION \n",
    "#for epoch in range(4):\n",
    "#    B2 = (Y-Yhat) * sigmoid_derivative(S)\n",
    "#    G2 = B2.T.dot( H )\n",
    "#    B1 = B2.dot(W[1])*sigmoid_derivative(T)\n",
    "#    G1 = B1.T.dot( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setParameters(X, Y, hidden_size):\n",
    "  np.random.seed(3)\n",
    "  input_size = X.shape[0] # number of neurons in input layer\n",
    "  output_size = Y.shape[0] # number of neurons in output layer.\n",
    "  W1 = np.random.randn(hidden_size, input_size)*np.sqrt(2/input_size)\n",
    "  b1 = np.zeros((hidden_size, 1))\n",
    "  W2 = np.random.randn(output_size, hidden_size)*np.sqrt(2/hidden_size)\n",
    "  b2 = np.zeros((output_size, 1))\n",
    "  return {'W1': W1, 'W2': W2, 'b1': b1, 'b2': b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagation(X, params):\n",
    "  Z1 = np.dot(params['W1'], X)+params['b1']\n",
    "  A1 = np.tanh(Z1)\n",
    "  Z2 = np.dot(params['W2'], A1)+params['b2']\n",
    "  y = sigmoid(Z2)  \n",
    "  return y, {'Z1': Z1, 'Z2': Z2, 'A1': A1, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(predict, actual):\n",
    "  m = actual.shape[1]\n",
    "  cost__ = -np.sum(np.multiply(np.log(predict), actual) + np.multiply((1 - actual), np.log(1 - predict)))/m\n",
    "  return np.squeeze(cost__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(X, Y, params, cache):\n",
    "  m = X.shape[1]\n",
    "  dy = cache['y'] - Y\n",
    "  dW2 = (1 / m) * np.dot(dy, np.transpose(cache['A1']))\n",
    "  db2 = (1 / m) * np.sum(dy, axis=1, keepdims=True)\n",
    "  dZ1 = np.dot(np.transpose(params['W2']), dy) * (1-np.power(cache['A1'], 2))\n",
    "  dW1 = (1 / m) * np.dot(dZ1, np.transpose(X))\n",
    "  db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "  return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParameters(gradients, params, learning_rate = 1.2):\n",
    "    W1 = params['W1'] - learning_rate * gradients['dW1']\n",
    "    b1 = params['b1'] - learning_rate * gradients['db1']\n",
    "    W2 = params['W2'] - learning_rate * gradients['dW2']\n",
    "    b2 = params['b2'] - learning_rate * gradients['db2']\n",
    "    return {'W1': W1, 'W2': W2, 'b1': b1, 'b2': b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, Y, learning_rate, hidden_size, number_of_iterations = 5000):\n",
    "  params = setParameters(X, Y, hidden_size)\n",
    "  cost_ = []\n",
    "  for j in range(number_of_iterations):\n",
    "    y, cache = forwardPropagation(X, params)\n",
    "    costit = cost(y, Y)\n",
    "    gradients = backPropagation(X, Y, params, cache)\n",
    "    params = updateParameters(gradients, params, learning_rate)\n",
    "    cost_.append(costit)\n",
    "  return params, cost_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
